{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import sys, pickle\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, f1_score\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Model, load_model\n",
    "from keras.layers import Dense\n",
    "\n",
    "from keras.applications.vgg19 import VGG19\n",
    "from keras.applications.vgg19 import preprocess_input as VGG19_preprocess\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.applications.inception_v3 import preprocess_input as InceotionV3_preprocess\n",
    "from keras.applications.resnet_v2 import ResNet50V2\n",
    "from keras.applications.resnet_v2 import preprocess_input as ResNet50V2_preprocess\n",
    "from keras.applications.inception_resnet_v2 import InceptionResNetV2\n",
    "from keras.applications.inception_resnet_v2 import preprocess_input as InceptionResNetV2_preprocess\n",
    "\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
    "\n",
    "import tensorflow as tf\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "keras.backend.set_session(tf.Session(config=config))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_dim = 384"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8000, 384, 384, 3) (8000, 1)\n"
     ]
    }
   ],
   "source": [
    "with open('kvasir_cls_'+str(image_dim)+'.pickle', 'rb') as f:\n",
    "    [X,Y] = pickle.load(f)\n",
    "    print(X.shape, Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert np.max(X) == 255\n",
    "assert np.min(X) == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:368: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "enc = OneHotEncoder(sparse=False)\n",
    "Y_enc = enc.fit_transform(Y)\n",
    "n_class = Y_enc.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_trnval, X_tst, Y_trnval, Y_tst = train_test_split(X, Y_enc, test_size = 1200, random_state = 27407, stratify = Y_enc)\n",
    "X_trn, X_val, Y_trn, Y_val = train_test_split(X_trnval, Y_trnval, test_size = 1200, random_state = 27407, stratify = Y_trnval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trn.shape (5600, 384, 384, 3) (5600, 8)\n",
      "val.shape (1200, 384, 384, 3) (1200, 8)\n",
      "tst.shape (1200, 384, 384, 3) (1200, 8)\n"
     ]
    }
   ],
   "source": [
    "print('trn.shape', X_trn.shape, Y_trn.shape)\n",
    "print('val.shape', X_val.shape, Y_val.shape)\n",
    "print('tst.shape', X_tst.shape, Y_tst.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\user\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\user\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\user\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\user\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4267: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\user\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\user\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if model_id == 1: \n",
    "    base_model = VGG19(weights = 'imagenet', pooling='avg', include_top =False)\n",
    "    preprocess_func = VGG19_preprocess\n",
    "elif model_id == 2: \n",
    "    base_model = InceptionV3(weights = 'imagenet', pooling='avg', include_top = False)\n",
    "    preprocess_func = InceptionV3_preprocess\n",
    "elif model_id == 3: \n",
    "    base_model = ResNet50V2(weights = 'imagenet', pooling='avg', include_top = False)\n",
    "    preprocess_func = ResNet50V2_preprocess\n",
    "elif model_id == 4: \n",
    "    base_model = InceptionResNetV2(weights = 'imagenet', pooling='avg', include_top = False)\n",
    "    preprocess_func = InceptionResNetV2_preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = Dense(8, activation='softmax')(base_model.output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, None, None, 3)     0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, None, None, 64)    1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, None, None, 64)    36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, None, None, 64)    0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, None, None, 128)   73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, None, None, 128)   147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, None, None, 128)   0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, None, None, 256)   295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, None, None, 256)   590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, None, None, 256)   590080    \n",
      "_________________________________________________________________\n",
      "block3_conv4 (Conv2D)        (None, None, None, 256)   590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, None, None, 256)   0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, None, None, 512)   1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv4 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, None, None, 512)   0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv4 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, None, None, 512)   0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_1 ( (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 8)                 4104      \n",
      "=================================================================\n",
      "Total params: 20,028,488\n",
      "Trainable params: 20,028,488\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Model(inputs = base_model.input, outputs = predictions)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_gen_args = dict(rotation_range = 360, width_shift_range=0.15, height_shift_range=0.15, zoom_range=0.15, \n",
    "                     brightness_range=[0.5, 1.5], horizontal_flip=True, vertical_flip=False, fill_mode='constant', cval=0)\n",
    "\n",
    "generator = ImageDataGenerator(**data_gen_args, preprocessing_function = preprocess_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_flow = generator.flow(X_trn, Y_trn, batch_size = batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val = preprocess_func(X_val)\n",
    "X_tst = preprocess_func(X_tst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":: training\n",
      "WARNING:tensorflow:From C:\\Users\\user\\Anaconda3\\lib\\site-packages\\keras\\optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(':: training')\n",
    "for layer in base_model.layers: layer.trainable = True\n",
    "model.compile(optimizer = Adam(lr=1e-5), loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "earlystopper = EarlyStopping(monitor= 'val_loss', patience=20, restore_best_weights=True, verbose=1)\n",
    "reduce_lr = ReduceLROnPlateau(monitor= 'val_loss', factor=0.1, patience=10, min_lr = 1e-8, verbose=1)\n",
    "mcp_save = ModelCheckpoint('kvasir_cls_'+str(model_id)+'.h5', save_best_only=True, monitor='val_accuracy', mode='max')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\user\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "Epoch 1/500\n",
      " - 208s - loss: 0.7231 - acc: 0.7182 - val_loss: 0.3534 - val_acc: 0.8558\n",
      "Epoch 2/500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\keras\\callbacks.py:707: RuntimeWarning: Can save best model only with val_accuracy available, skipping.\n",
      "  'skipping.' % (self.monitor), RuntimeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 200s - loss: 0.3722 - acc: 0.8484 - val_loss: 0.3243 - val_acc: 0.8708\n",
      "Epoch 3/500\n",
      " - 201s - loss: 0.3111 - acc: 0.8779 - val_loss: 0.3163 - val_acc: 0.8675\n",
      "Epoch 4/500\n",
      " - 201s - loss: 0.2870 - acc: 0.8898 - val_loss: 0.2419 - val_acc: 0.9092\n",
      "Epoch 5/500\n",
      " - 201s - loss: 0.2409 - acc: 0.9071 - val_loss: 0.2869 - val_acc: 0.8950\n",
      "Epoch 6/500\n",
      " - 201s - loss: 0.2423 - acc: 0.9054 - val_loss: 0.3030 - val_acc: 0.8808\n",
      "Epoch 7/500\n",
      " - 201s - loss: 0.2327 - acc: 0.9080 - val_loss: 0.2217 - val_acc: 0.9050\n",
      "Epoch 8/500\n",
      " - 201s - loss: 0.2142 - acc: 0.9152 - val_loss: 0.2258 - val_acc: 0.9125\n",
      "Epoch 9/500\n",
      " - 200s - loss: 0.2041 - acc: 0.9193 - val_loss: 0.2810 - val_acc: 0.9075\n",
      "Epoch 10/500\n",
      " - 200s - loss: 0.1889 - acc: 0.9275 - val_loss: 0.2604 - val_acc: 0.9067\n",
      "Epoch 11/500\n",
      " - 200s - loss: 0.1942 - acc: 0.9239 - val_loss: 0.2417 - val_acc: 0.9142\n",
      "Epoch 12/500\n",
      " - 200s - loss: 0.1773 - acc: 0.9316 - val_loss: 0.2288 - val_acc: 0.9092\n",
      "Epoch 13/500\n",
      " - 200s - loss: 0.1751 - acc: 0.9377 - val_loss: 0.2207 - val_acc: 0.9275\n",
      "Epoch 14/500\n",
      " - 200s - loss: 0.1719 - acc: 0.9352 - val_loss: 0.2240 - val_acc: 0.9150\n",
      "Epoch 15/500\n",
      " - 200s - loss: 0.1647 - acc: 0.9334 - val_loss: 0.2035 - val_acc: 0.9225\n",
      "Epoch 16/500\n",
      " - 200s - loss: 0.1594 - acc: 0.9355 - val_loss: 0.2231 - val_acc: 0.9192\n",
      "Epoch 17/500\n",
      " - 200s - loss: 0.1541 - acc: 0.9418 - val_loss: 0.1923 - val_acc: 0.9317\n",
      "Epoch 18/500\n",
      " - 200s - loss: 0.1489 - acc: 0.9439 - val_loss: 0.2597 - val_acc: 0.9050\n",
      "Epoch 19/500\n",
      " - 200s - loss: 0.1444 - acc: 0.9446 - val_loss: 0.2805 - val_acc: 0.9100\n",
      "Epoch 20/500\n",
      " - 200s - loss: 0.1445 - acc: 0.9427 - val_loss: 0.2012 - val_acc: 0.9283\n",
      "Epoch 21/500\n",
      " - 200s - loss: 0.1431 - acc: 0.9443 - val_loss: 0.2378 - val_acc: 0.9217\n",
      "Epoch 22/500\n",
      " - 200s - loss: 0.1370 - acc: 0.9487 - val_loss: 0.2396 - val_acc: 0.9192\n",
      "Epoch 23/500\n",
      " - 200s - loss: 0.1252 - acc: 0.9479 - val_loss: 0.2616 - val_acc: 0.9125\n",
      "Epoch 24/500\n",
      " - 200s - loss: 0.1248 - acc: 0.9518 - val_loss: 0.2392 - val_acc: 0.9142\n",
      "Epoch 25/500\n",
      " - 200s - loss: 0.1333 - acc: 0.9491 - val_loss: 0.2129 - val_acc: 0.9183\n",
      "Epoch 26/500\n",
      " - 200s - loss: 0.1070 - acc: 0.9571 - val_loss: 0.2385 - val_acc: 0.9217\n",
      "Epoch 27/500\n",
      " - 200s - loss: 0.1184 - acc: 0.9518 - val_loss: 0.2528 - val_acc: 0.9108\n",
      "\n",
      "Epoch 00027: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-07.\n",
      "Epoch 28/500\n",
      " - 200s - loss: 0.0777 - acc: 0.9721 - val_loss: 0.1913 - val_acc: 0.9325\n",
      "Epoch 29/500\n",
      " - 200s - loss: 0.0660 - acc: 0.9741 - val_loss: 0.1937 - val_acc: 0.9300\n",
      "Epoch 30/500\n",
      " - 200s - loss: 0.0608 - acc: 0.9762 - val_loss: 0.2026 - val_acc: 0.9308\n",
      "Epoch 31/500\n",
      " - 200s - loss: 0.0592 - acc: 0.9777 - val_loss: 0.2048 - val_acc: 0.9358\n",
      "Epoch 32/500\n",
      " - 200s - loss: 0.0557 - acc: 0.9814 - val_loss: 0.2064 - val_acc: 0.9308\n",
      "Epoch 33/500\n",
      " - 202s - loss: 0.0526 - acc: 0.9809 - val_loss: 0.2144 - val_acc: 0.9275\n",
      "Epoch 34/500\n",
      " - 203s - loss: 0.0480 - acc: 0.9830 - val_loss: 0.2295 - val_acc: 0.9267\n",
      "Epoch 35/500\n",
      " - 202s - loss: 0.0513 - acc: 0.9795 - val_loss: 0.2348 - val_acc: 0.9267\n",
      "Epoch 36/500\n"
     ]
    }
   ],
   "source": [
    "model.fit_generator(data_flow, steps_per_epoch=np.ceil(len(X_trn)/batch_size), epochs=500, validation_data=(X_val, Y_val),\n",
    "                   callbacks=[earlystopper, reduce_lr, mcp_save], verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
